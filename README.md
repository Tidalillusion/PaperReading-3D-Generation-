# PaperReading-3D-Generation
<p>This repository is built to record the paper I have read for me to revise.<br>  Hope that by writing and sharing, I coulde make progress.</p>
<P> 
The Table 1 is the paper that I have intensive reading, so there will be detailed information about this paper. If I have read the code, I will show my understanding about it.<br>
The Table 2 is the paper that I have skimmed, so there will just abound with something interesting for me.<br>

# Table 1(Intensive Reading) 
| Title | Author | Source | Overview |
| ---   | ---     | --- | ---|
|SceneDreamer: Unbounded 3D Scene Generation from 2D Image Collections<br> [DooDoo's Note](https://github.com/Tidalillusion/PaperReading-3D-Generation-/blob/main/Read/SceneDreamer.md)<br>[arxiv](https://arxiv.org/abs/2302.01330#)<br>[Github](https://github.com/FrozenBurning/SceneDreamer) |Zhaoxi Chen, Guangcong Wang, and Ziwei Liu<br>S-LAB 南洋理工大学|TPAMI 2023|1.2023年来提出的首个无边界生成模型，生成结果较好地保持了风格一致性与内容连续性。<br>2.模型训练的数据为无标注的、分辨率、场景不统一的自然影像数据。<br>3.提出了BEV presentation来表示数据，并提出了Neural Hash Grid结构来处理数据，提升了模型容量、生成效率、效果。|

# table 2(skimming)
